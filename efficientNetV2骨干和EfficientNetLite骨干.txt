我要把别人的东西总结成自己的知识,自己能看得懂就行,有些东西言语表达未必能表达好

def conv_kernel_initializer(scale=2.0):
    return keras.initializers.VarianceScaling(
        scale=scale, mode="fan_out", distribution="truncated_normal"
    )
def round_filters(filters, width_coefficient, min_depth, depth_divisor):
    filters *= width_coefficient
    minimum_depth = min_depth or depth_divisor
    new_filters = max(
        minimum_depth,
        int(filters + depth_divisor / 2) // depth_divisor * depth_divisor,
    )
    return int(new_filters)
def round_repeats(repeats, depth_coefficient):
    return int(math.ceil(depth_coefficient * repeats))
BN_AXIS = 3 # 特征轴
CONV_KERNEL_INITIALIZER = { # 核初始化
    "class_name": "VarianceScaling", # 方差比例
    "config": {
        "scale": 2.0,
        "mode": "fan_out",
        "distribution": "truncated_normal",
    },
}
# 融合卷积
@keras_cv_export("keras_cv.layers.FusedMBConvBlock")
class FusedMBConvBlock(keras.layers.Layer):
    def __init__(
        self,
        input_filters: int,
        output_filters: int,
        expand_ratio=1,
        kernel_size=3,
        strides=1,
        se_ratio=0.0,
        bn_momentum=0.9,
        activation="swish",
        survival_probability: float = 0.8,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.input_filters = input_filters
        self.output_filters = output_filters
        self.expand_ratio = expand_ratio
        self.kernel_size = kernel_size
        self.strides = strides
        self.se_ratio = se_ratio
        self.bn_momentum = bn_momentum
        self.activation = activation
        self.survival_probability = survival_probability
        self.filters = self.input_filters * self.expand_ratio
        self.filters_se = max(1, int(input_filters * se_ratio))
        # 具有指定内核大小和步幅的卷积层，而不是1x1 扩张卷积
        self.conv1 = keras.layers.Conv2D(
            filters=self.filters,
            kernel_size=kernel_size,
            strides=strides,
            kernel_initializer=CONV_KERNEL_INITIALIZER,
            padding="same",
            data_format="channels_last",
            use_bias=False,
            name=self.name + "expand_conv",
        )
        self.bn1 = keras.layers.BatchNormalization(
            axis=BN_AXIS,
            momentum=self.bn_momentum,
            name=self.name + "expand_bn",
        )
        self.act = keras.layers.Activation(
            self.activation, name=self.name + "expand_activation"
        )

        self.bn2 = keras.layers.BatchNormalization(
            axis=BN_AXIS, momentum=self.bn_momentum, name=self.name + "bn"
        )
        # 挤压点卷积
        self.se_conv1 = keras.layers.Conv2D(
            self.filters_se,
            1,
            padding="same",
            activation=self.activation,
            kernel_initializer=CONV_KERNEL_INITIALIZER,
            name=self.name + "se_reduce",
        )
        # 激励点卷积
        self.se_conv2 = keras.layers.Conv2D(
            self.filters,
            1,
            padding="same",
            activation="sigmoid",
            kernel_initializer=CONV_KERNEL_INITIALIZER,
            name=self.name + "se_expand",
        )
        # 看扩张比例,如果是1,应该是普通卷积,否则是点卷积
        self.output_conv = keras.layers.Conv2D(
            filters=self.output_filters,
            kernel_size=1 if expand_ratio != 1 else kernel_size,
            strides=1,
            kernel_initializer=CONV_KERNEL_INITIALIZER,
            padding="same",
            data_format="channels_last",
            use_bias=False,
            name=self.name + "project_conv",
        )
        self.bn3 = keras.layers.BatchNormalization(
            axis=BN_AXIS,
            momentum=self.bn_momentum,
            name=self.name + "project_bn",
        )

        if self.survival_probability:
            self.dropout = keras.layers.Dropout(
                self.survival_probability,
                noise_shape=(None, 1, 1, 1),
                name=self.name + "drop",
            )
    def build(self, input_shape):
        if self.name is None:
            self.name = keras.backend.get_uid("block0")

    def call(self, inputs):
        # 扩张阶段,如果expand_ratio== 1,不改变,否则用具有指定内核大小和步幅的卷积,
        # 而不是先进行 1x1 扩张卷积，这时用的是普通卷积
        if self.expand_ratio != 1:
            x = self.conv1(inputs)
            x = self.bn1(x)
            x = self.act(x)
        else:
            x = inputs
        # se块(使用的条件是0<se_ratio <= 1)
        if 0 < self.se_ratio <= 1:
            # 全局平均池化
            se = keras.layers.GlobalAveragePooling2D(
                name=self.name + "se_squeeze"
            )(x)
            if BN_AXIS == 1:
                se_shape = (self.filters, 1, 1)
            else:
                se_shape = (1, 1, self.filters)
            # 变形
            se = keras.layers.Reshape(se_shape, name=self.name + "se_reshape")(
                se
            )
            # 压缩激励,用sigmoid打分
            se = self.se_conv1(se)
            se = self.se_conv2(se)
            # 通道加权
            x = keras.layers.multiply([x, se], name=self.name + "se_excite")
        # 输出阶段,如果expand_ratio 等于 1,使用普通卷积,否则使用 1x1 卷积降低通道数，并进行批量归一化。如果
        # expand_ratio 等于 1，则在输出卷积后应用激活函数。
        x = self.output_conv(x)
        x = self.bn3(x)
        if self.expand_ratio == 1:
            x = self.act(x)
        # 残差,条件是strides == 1 and input_filters == output_filters
        if self.strides == 1 and self.input_filters == self.output_filters:
            if self.survival_probability:
                x = self.dropout(x)
            x = keras.layers.Add(name=self.name + "add")([x, inputs])
        return x
    # 获取配置
    def get_config(self):
        config = {
            "input_filters": self.input_filters,
            "output_filters": self.output_filters,
            "expand_ratio": self.expand_ratio,
            "kernel_size": self.kernel_size,
            "strides": self.strides,
            "se_ratio": self.se_ratio,
            "bn_momentum": self.bn_momentum,
            "activation": self.activation,
            "survival_probability": self.survival_probability,
        }

        base_config = super().get_config()
        return dict(list(base_config.items()) + list(config.items()))
# MBConv块是在面向移动设备和高效的架构中常用的模块，出现在诸如MobileNet、EfficientNet、MaxViT等架构中。
# MBConv块遵循窄-宽-窄的结构——通过扩展1x1卷积，应用深度卷积，然后缩小回1x1卷积，这比传统的宽-窄-宽结构更有效率。
# 由于这些模块经常用于部署到边缘设备的模型中，因此为了便于使用和复用，我们将其实现为一个层。
# 未融合的卷积
@keras_cv_export("keras_cv.layers.MBConvBlock")
class MBConvBlock(keras.layers.Layer):
    def __init__(
        self,
        input_filters: int,
        output_filters: int,
        expand_ratio=1,
        kernel_size=3,
        strides=1,
        se_ratio=0.0,
        bn_momentum=0.9,
        activation="swish",
        survival_probability: float = 0.8,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.input_filters = input_filters
        self.output_filters = output_filters
        self.expand_ratio = expand_ratio
        self.kernel_size = kernel_size
        self.strides = strides
        self.se_ratio = se_ratio
        self.bn_momentum = bn_momentum
        self.activation = activation
        self.survival_probability = survival_probability
        self.filters = self.input_filters * self.expand_ratio # 内部通道数
        self.filters_se = max(1, int(input_filters * se_ratio)) # 挤压通道数
        # 扩张点卷积
        self.conv1 = keras.layers.Conv2D(
            filters=self.filters,
            kernel_size=1,
            strides=1,
            kernel_initializer=CONV_KERNEL_INITIALIZER,
            padding="same",
            data_format="channels_last",
            use_bias=False,
            name=self.name + "expand_conv",
        )
        # 批次标准化
        self.bn1 = keras.layers.BatchNormalization(
            axis=BN_AXIS,
            momentum=self.bn_momentum,
            name=self.name + "expand_bn",
        )
        self.act = keras.layers.Activation( # 激活函数
            self.activation, name=self.name + "activation"
        )
        self.depthwise = keras.layers.DepthwiseConv2D( # 深度卷积
            kernel_size=self.kernel_size,
            strides=self.strides,
            depthwise_initializer=CONV_KERNEL_INITIALIZER,
            padding="same",
            data_format="channels_last",
            use_bias=False,
            name=self.name + "dwconv2",
        )
        self.bn2 = keras.layers.BatchNormalization(
            axis=BN_AXIS, momentum=self.bn_momentum, name=self.name + "bn"
        )
        # 挤压点卷积
        self.se_conv1 = keras.layers.Conv2D(
            self.filters_se,
            1,
            padding="same",
            activation=self.activation,
            kernel_initializer=CONV_KERNEL_INITIALIZER,
            name=self.name + "se_reduce",
        )
        # 激励点卷积,sigmoid会给每个通道单独打分
        self.se_conv2 = keras.layers.Conv2D(
            self.filters,
            1,
            padding="same",
            activation="sigmoid",
            kernel_initializer=CONV_KERNEL_INITIALIZER,
            name=self.name + "se_expand",
        )
        
        self.output_conv = keras.layers.Conv2D(
            filters=self.output_filters,
            # 这意味着扩张比例是1时,核大小可以不是1,那就是普通卷积
            kernel_size=1 if expand_ratio != 1 else kernel_size,
            strides=1,
            kernel_initializer=CONV_KERNEL_INITIALIZER,
            padding="same",
            data_format="channels_last",
            use_bias=False,
            name=self.name + "project_conv",
        )

        self.bn3 = keras.layers.BatchNormalization(
            axis=BN_AXIS,
            momentum=self.bn_momentum,
            name=self.name + "project_bn",
        )
        # dropout,noise_shape=(None, 1, 1, 1)
        if self.survival_probability:
            self.dropout = keras.layers.Dropout(
                self.survival_probability,
                noise_shape=(None, 1, 1, 1),
                name=self.name + "drop",
            )

    def build(self, input_shape):
        if self.name is None:
            self.name = keras.backend.get_uid("block0")
    
    def call(self, inputs): # inputs:(b,h,w,c)
        # 扩张阶段,如果扩张比例不等于1,用扩张卷积,否则不改变
        if self.expand_ratio != 1:
            # 扩张卷积块
            x = self.conv1(inputs)
            x = self.bn1(x)
            x = self.act(x)
        else:
            x = inputs
        # 深度卷积块
        x = self.depthwise(x)
        x = self.bn2(x)
        x = self.act(x)
        # se块,全局平均池化,获取通道描述符,之后压缩激励,打分加权
        if 0 < self.se_ratio <= 1:
            se = keras.layers.GlobalAveragePooling2D(
                name=self.name + "se_squeeze"
            )(x)
            if BN_AXIS == 1:
                se_shape = (self.filters, 1, 1)
            else:
                se_shape = (1, 1, self.filters)
            se = keras.layers.Reshape(se_shape, name=self.name + "se_reshape")(
                se
            )
            se = self.se_conv1(se)
            se = self.se_conv2(se)
            x = keras.layers.multiply([x, se], name=self.name + "se_excite")
        # 输出阶段
        x = self.output_conv(x)
        x = self.bn3(x)
        # 残差连接,条件是步长是1,并且输入输出通道数相同
        if self.strides == 1 and self.input_filters == self.output_filters:
            if self.survival_probability:
                x = self.dropout(x)
            x = keras.layers.Add(name=self.name + "add")([x, inputs])
        return x
    def get_config(self):
        # 子类特有的配置(字典)
        config = {
            "input_filters": self.input_filters,
            "output_filters": self.output_filters,
            "expand_ratio": self.expand_ratio,
            "kernel_size": self.kernel_size,
            "strides": self.strides,
            "se_ratio": self.se_ratio,
            "bn_momentum": self.bn_momentum,
            "activation": self.activation,
            "survival_probability": self.survival_probability,
        }
        # 获取父类的配置
        base_config = super().get_config()
        # 返回合并的配置
        return dict(list(base_config.items()) + list(config.items()))
# 获取conv构造函数,如果传入"unfused",就使用MBConvBlock,否则使用FusedMBConvBlock
def get_conv_constructor(conv_type):
    if conv_type == "unfused": # 未融合,点卷积和深度卷积组合,这个用于网络的后部分
        return MBConvBlock
    elif conv_type == "fused": # 融合,就是普通卷积,这个用于网络的前部分
        return FusedMBConvBlock
    else:
        raise ValueError(
            "Expected `conv_type` to be "
            "one of 'unfused', 'fused', but got "
            f"`conv_type={conv_type}`"
        )
# 这个注解用于提供外部访问这个类的导入路径
@keras_cv_export("keras_cv.models.EfficientNetV2Backbone")
class EfficientNetV2Backbone(Backbone):
    def __init__(
        self,
        *,
        include_rescaling,
        width_coefficient,
        depth_coefficient,
        stackwise_kernel_sizes,
        stackwise_num_repeats,
        stackwise_input_filters,
        stackwise_output_filters,
        stackwise_expansion_ratios,
        stackwise_squeeze_and_excite_ratios,
        stackwise_strides,
        stackwise_conv_types,
        skip_connection_dropout=0.2,
        depth_divisor=8,
        min_depth=8,
        activation="swish",
        input_shape=(None, None, 3),
        input_tensor=None,
        **kwargs,
    ):
        # 确定合适的输入
        img_input = utils.parse_model_inputs(input_shape, input_tensor)
        x = img_input
        if include_rescaling:
            x = keras.layers.Rescaling(scale=1 / 255.0)(x) # 归一化
        # 规范化卷积通道数(一般是8的倍数)
        stem_filters = round_filters(
            filters=stackwise_input_filters[0],
            width_coefficient=width_coefficient,
            min_depth=min_depth,
            depth_divisor=depth_divisor,
        )
        # 第一个下采样块(112,112,3)
        x = keras.layers.Conv2D(
            filters=stem_filters,
            kernel_size=3,
            strides=2,
            kernel_initializer=conv_kernel_initializer(),
            padding="same",
            use_bias=False,
            name="stem_conv",
        )(x)
        x = keras.layers.BatchNormalization(
            momentum=0.9,
            name="stem_bn",
        )(x)
        x = keras.layers.Activation(activation, name="stem_activation")(x)
        
        # 提取块的块索引
        block_id = 0
        blocks = float( # 总的提取块数
            sum(num_repeats for num_repeats in stackwise_num_repeats)
        )
        # 金字塔层级的特征图层名列表
        pyramid_level_inputs = []
        # 遍历每个层级
        for i in range(len(stackwise_kernel_sizes)):
            num_repeats = stackwise_num_repeats[i] # 指定层级的重复提取次数
            input_filters = stackwise_input_filters[i] # 卷积的输入通道数
            output_filters = stackwise_output_filters[i] # 卷积的输出通道数
            # 规范化输入输出通道数
            input_filters = round_filters(
                filters=input_filters,
                width_coefficient=width_coefficient,
                min_depth=min_depth,
                depth_divisor=depth_divisor,
            )
            output_filters = round_filters(
                filters=output_filters,
                width_coefficient=width_coefficient,
                min_depth=min_depth,
                depth_divisor=depth_divisor,
            )
            # 规范化重复次数
            repeats = round_repeats(
                repeats=num_repeats,
                depth_coefficient=depth_coefficient,
            )
            strides = stackwise_strides[i] # 步长
            squeeze_and_excite_ratio = stackwise_squeeze_and_excite_ratios[i] # 挤激比
            # 遍历一个层级下的每个提取块
            for j in range(repeats):
                # 如果不是第一个提取块,这时步长是1,并且输入和输出通道数相同
                if j > 0:
                    strides = 1
                    input_filters = output_filters
                # 步长等于2,这时把之前的特征图加入FPN
                if strides != 1:
                    pyramid_level_inputs.append(utils.get_tensor_input_name(x))
                # 用来设置提取块前缀,a...
                letter_identifier = chr(j + 97)
                block = get_conv_constructor(stackwise_conv_types[i])(
                    input_filters=input_filters,
                    output_filters=output_filters,
                    expand_ratio=stackwise_expansion_ratios[i], # 扩张比例
                    kernel_size=stackwise_kernel_sizes[i],
                    strides=strides,
                    se_ratio=squeeze_and_excite_ratio, # 挤激比
                    activation=activation,
                    # dropout比率,随着层级的加深,比率变大
                    survival_probability=skip_connection_dropout
                    * block_id
                    / blocks,
                    bn_momentum=0.9,
                    name="block{}{}_".format(i + 1, letter_identifier),
                )
                # 通过提取块处理
                x = block(x)
                block_id += 1 # 块计数器+1
        # 规范化顶部输出通道数
        top_filters = round_filters(
            filters=1280,
            width_coefficient=width_coefficient, # 宽度系数
            min_depth=min_depth,
            depth_divisor=depth_divisor, # 深度因子
        )
        # 点卷积切换通道
        x = keras.layers.Conv2D(
            filters=top_filters,
            kernel_size=1,
            strides=1,
            kernel_initializer=conv_kernel_initializer(),
            padding="same", # 填充
            data_format="channels_last",
            use_bias=False,
            name="top_conv",
        )(x)
        x = keras.layers.BatchNormalization(
            momentum=0.9,
            name="top_bn",
        )(x)
        x = keras.layers.Activation(
            activation=activation, name="top_activation"
        )(x)
        # FPN特征提取层列表
        pyramid_level_inputs.append(utils.get_tensor_input_name(x))

        # Create model.
        super().__init__(inputs=img_input, outputs=x, **kwargs)
        # 设置实例属性
        self.include_rescaling = include_rescaling
        self.width_coefficient = width_coefficient
        self.depth_coefficient = depth_coefficient
        self.skip_connection_dropout = skip_connection_dropout
        self.depth_divisor = depth_divisor
        self.min_depth = min_depth
        self.activation = activation
        self.input_tensor = input_tensor
        # FPN特征提取字典,idx-->name
        self.pyramid_level_inputs = {
            f"P{i + 1}": name for i, name in enumerate(pyramid_level_inputs)
        }
        # 各个层级的配置信息。
        self.stackwise_kernel_sizes = stackwise_kernel_sizes
        self.stackwise_num_repeats = stackwise_num_repeats
        self.stackwise_input_filters = stackwise_input_filters
        self.stackwise_output_filters = stackwise_output_filters
        self.stackwise_expansion_ratios = stackwise_expansion_ratios
        self.stackwise_squeeze_and_excite_ratios = (
            stackwise_squeeze_and_excite_ratios
        )
        self.stackwise_strides = stackwise_strides
        self.stackwise_conv_types = stackwise_conv_types
    # 配置,用于序列化和反序列化
    def get_config(self):
        # 获取父类的配置对象,字典形式
        config = super().get_config()
        config.update( # 更新子类独有的设置
            {
                "include_rescaling": self.include_rescaling,
                "width_coefficient": self.width_coefficient,
                "depth_coefficient": self.depth_coefficient,
                "skip_connection_dropout": self.skip_connection_dropout,
                "depth_divisor": self.depth_divisor,
                "min_depth": self.min_depth,
                "activation": self.activation,
                "input_shape": self.input_shape[1:],
                "input_tensor": self.input_tensor,
                "stackwise_kernel_sizes": self.stackwise_kernel_sizes,
                "stackwise_num_repeats": self.stackwise_num_repeats,
                "stackwise_input_filters": self.stackwise_input_filters,
                "stackwise_output_filters": self.stackwise_output_filters,
                "stackwise_expansion_ratios": self.stackwise_expansion_ratios,
                "stackwise_squeeze_and_excite_ratios": self.stackwise_squeeze_and_excite_ratios,  # noqa: E501
                "stackwise_strides": self.stackwise_strides,
                "stackwise_conv_types": self.stackwise_conv_types,
            }
        )
        return config
    # presets 是一个类属性，用于存储预设的配置信息
    @classproperty
    def presets(cls):
        return copy.deepcopy(backbone_presets)
    # 类属性,预设的权重
    @classproperty
    def presets_with_weights(cls):
        return copy.deepcopy(backbone_presets_with_weights)

backbone_presets_no_weights = {
    "efficientnetv2_s": {
        "metadata": {
            "description": (
                "EfficientNet architecture with 6 convolutional blocks."
            ),
            "params": 20331360,
            "official_name": "EfficientNetV2",
            "path": "efficientnetv2",
        },
        "kaggle_handle": "kaggle://keras/efficientnetv2/keras/efficientnetv2_s/2",  # noqa: E501
    },
    "efficientnetv2_m": {
        "metadata": {
            "description": (
                "EfficientNet architecture with 7 convolutional blocks."
            ),
            "params": 53150388,
            "official_name": "EfficientNetV2",
            "path": "efficientnetv2",
        },
        "kaggle_handle": "kaggle://keras/efficientnetv2/keras/efficientnetv2_m/2",  # noqa: E501
    },
    "efficientnetv2_l": {
        "metadata": {
            "description": (
                "EfficientNet architecture with 7 convolutional "
                "blocks, but more filters the in `efficientnetv2_m`."
            ),
            "params": 117746848,
            "official_name": "EfficientNetV2",
            "path": "efficientnetv2",
        },
        "kaggle_handle": "kaggle://keras/efficientnetv2/keras/efficientnetv2_l/2",  # noqa: E501
    },
    "efficientnetv2_b0": {
        "metadata": {
            "description": (
                "EfficientNet B-style architecture with 6 "
                "convolutional blocks. This B-style model has "
                "`width_coefficient=1.0` and `depth_coefficient=1.0`."
            ),
            "params": 5919312,
            "official_name": "EfficientNetV2",
            "path": "efficientnetv2",
        },
        "kaggle_handle": "kaggle://keras/efficientnetv2/keras/efficientnetv2_b0/2",  # noqa: E501
    },
    "efficientnetv2_b1": {
        "metadata": {
            "description": (
                "EfficientNet B-style architecture with 6 "
                "convolutional blocks. This B-style model has "
                "`width_coefficient=1.0` and `depth_coefficient=1.1`."
            ),
            "params": 6931124,
            "official_name": "EfficientNetV2",
            "path": "efficientnetv2",
        },
        "kaggle_handle": "kaggle://keras/efficientnetv2/keras/efficientnetv2_b1/2",  # noqa: E501
    },
    "efficientnetv2_b2": {
        "metadata": {
            "description": (
                "EfficientNet B-style architecture with 6 "
                "convolutional blocks. This B-style model has "
                "`width_coefficient=1.1` and `depth_coefficient=1.2`."
            ),
            "params": 8769374,
            "official_name": "EfficientNetV2",
            "path": "efficientnetv2",
        },
        "kaggle_handle": "kaggle://keras/efficientnetv2/keras/efficientnetv2_b2/2",  # noqa: E501
    },
    "efficientnetv2_b3": {
        "metadata": {
            "description": (
                "EfficientNet B-style architecture with 7 "
                "convolutional blocks. This B-style model has "
                "`width_coefficient=1.2` and `depth_coefficient=1.4`."
            ),
            "params": 12930622,
            "official_name": "EfficientNetV2",
            "path": "efficientnetv2",
        },
        "kaggle_handle": "kaggle://keras/efficientnetv2/keras/efficientnetv2_b3/2",  # noqa: E501
    },
}
backbone_presets_with_weights = {
    "efficientnetv2_s_imagenet": {
        "metadata": {
            "description": (
                "EfficientNet architecture with 6 convolutional "
                "blocks. Weights are initialized to pretrained imagenet "
                "classification weights.Published weights are capable of "
                "scoring 83.9%top 1 accuracy "
                "and 96.7% top 5 accuracy on imagenet."
            ),
            "params": 20331360,
            "official_name": "EfficientNetV2",
            "path": "efficientnetv2",
        },
        "kaggle_handle": "kaggle://keras/efficientnetv2/keras/efficientnetv2_s_imagenet/2",  # noqa: E501
    },
    "efficientnetv2_b0_imagenet": {
        "metadata": {
            "description": (
                "EfficientNet B-style architecture with 6 "
                "convolutional blocks. This B-style model has "
                "`width_coefficient=1.0` and `depth_coefficient=1.0`. "
                "Weights are "
                "initialized to pretrained imagenet classification weights. "
                "Published weights are capable of scoring 77.1%    top 1 accuracy "
                "and 93.3% top 5 accuracy on imagenet."
            ),
            "params": 5919312,
            "official_name": "EfficientNetV2",
            "path": "efficientnetv2",
        },
        "kaggle_handle": "kaggle://keras/efficientnetv2/keras/efficientnetv2_b0_imagenet/2",  # noqa: E501
    },
    "efficientnetv2_b1_imagenet": {
        "metadata": {
            "description": (
                "EfficientNet B-style architecture with 6 "
                "convolutional blocks. This B-style model has "
                "`width_coefficient=1.0` and `depth_coefficient=1.1`. "
                "Weights are "
                "initialized to pretrained imagenet classification weights."
                "Published weights are capable of scoring 79.1%    top 1 accuracy "
                "and 94.4% top 5 accuracy on imagenet."
            ),
            "params": 6931124,
            "official_name": "EfficientNetV2",
            "path": "efficientnetv2",
        },
        "kaggle_handle": "kaggle://keras/efficientnetv2/keras/efficientnetv2_b1_imagenet/2",  # noqa: E501
    },
    "efficientnetv2_b2_imagenet": {
        "metadata": {
            "description": (
                "EfficientNet B-style architecture with 6 "
                "convolutional blocks. This B-style model has "
                "`width_coefficient=1.1` and `depth_coefficient=1.2`. "
                "Weights are initialized to pretrained "
                "imagenet classification weights."
                "Published weights are capable of scoring 80.1%    top 1 accuracy "
                "and 94.9% top 5 accuracy on imagenet."
            ),
            "params": 8769374,
            "official_name": "EfficientNetV2",
            "path": "efficientnetv2",
        },
        "kaggle_handle": "kaggle://keras/efficientnetv2/keras/efficientnetv2_b2_imagenet/2",  # noqa: E501
    },
}
# 通过合并 backbone_presets_no_weights 和 backbone_presets_with_weights，形成一个完整的字典，包含所有预设配置。
backbone_presets = {
    **backbone_presets_no_weights,
    **backbone_presets_with_weights,
}

# 核初始化
def conv_kernel_initializer(scale=2.0):
    return keras.initializers.VarianceScaling(
        scale=scale, mode="fan_out", distribution="truncated_normal"
    )
# 确保通道数是depth_divisor的倍数
def round_filters(filters, depth_divisor, width_coefficient):
    filters *= width_coefficient
    new_filters = max(
        depth_divisor,
        int(filters + depth_divisor / 2) // depth_divisor * depth_divisor,
    )
    if new_filters < 0.9 * filters:
        new_filters += depth_divisor
    return int(new_filters)
# 堆叠块的深度
def round_repeats(repeats, depth_coefficient):
    return int(math.ceil(depth_coefficient * repeats))

def apply_efficient_net_lite_block(
    inputs,
    activation="relu6",
    dropout_rate=0.0,
    name=None,
    filters_in=32,
    filters_out=16,
    kernel_size=3,
    strides=1,
    expand_ratio=1,
):
    # 设置默认的块前缀
    if name is None:
        name = f"block_{keras.backend.get_uid('block_')}_"

    # 扩张阶段
    filters = filters_in * expand_ratio # 内部通道数
    # 如果扩张系数!=1,用扩张点卷积切换通道数
    if expand_ratio != 1:
        x = keras.layers.Conv2D(
            filters,
            1,
            padding="same",
            use_bias=False,
            kernel_initializer=conv_kernel_initializer(),
            name=name + "expand_conv",
        )(inputs)
        # 批次激活块
        x = keras.layers.BatchNormalization(
            axis=BN_AXIS, name=name + "expand_bn"
        )(x)
        x = keras.layers.Activation(
            activation, name=name + "expand_activation"
        )(x)
    else: # 扩张系数==1,不改变,x是中间变量
        x = inputs

    # 设置正确的填充
    if strides == 2:
        x = keras.layers.ZeroPadding2D(
            padding=utils.correct_pad_downsample(x, kernel_size),
            name=name + "dwconv_pad",
        )(x)
        conv_pad = "valid"
    else:
        conv_pad = "same"
    # 深度卷积,用于提取空间特征
    x = keras.layers.DepthwiseConv2D(
        kernel_size,
        strides=strides,
        padding=conv_pad,
        use_bias=False,
        depthwise_initializer=conv_kernel_initializer(),
        name=name + "dwconv",
    )(x)
    # 批次激活块
    x = keras.layers.BatchNormalization(axis=BN_AXIS, name=name + "bn")(x)
    x = keras.layers.Activation(activation, name=name + "activation")(x)

    # 输出阶段,点卷积切换通道
    x = keras.layers.Conv2D(
        filters_out,
        1,
        padding="same",
        use_bias=False,
        kernel_initializer=conv_kernel_initializer(),
        name=name + "project_conv",
    )(x)
    # 在最后一个轴做批次标准化
    x = keras.layers.BatchNormalization(axis=BN_AXIS, name=name + "project_bn")(
        x
    )
    #残差连接,条件:步长==1,并且输入和输出通道数相同
    if strides == 1 and filters_in == filters_out:
        # 如果有dropout,noise_shape=(None, 1, 1, 1)
        # 对于特征图的空间一致性要求较高的任务：比如物体检测、分割等任务，通常需要特征图在空间上具有一致性，
        # 这时使用 noise_shape=(None, 1, 1, 1) 更合适。
        if dropout_rate > 0:
            x = keras.layers.Dropout(
                dropout_rate, noise_shape=(None, 1, 1, 1), name=name + "drop"
            )(x)
        x = keras.layers.Add(name=name + "add")([x, inputs])
    # 如果用了残差,返回的就是残差后的结果,否则,返回的是bn后的结果
    return x
# keras_cv_export注解提供了从外部导入本类的路径
# keras.saving.register_keras_serializable用于注册一个类为可序列化的 Keras 对象。这意味着该类
# 可以被 Keras 自动保存和加载，从而支持模型的持久化操作。
@keras_cv_export("keras_cv.models.EfficientNetLiteBackbone")
@keras.saving.register_keras_serializable(package="keras_cv.models")
class EfficientNetLiteBackbone(Backbone):
    def __init__(
        self,
        *,
        include_rescaling, # 是否在内部归一化数据
        width_coefficient, # 宽度系数
        depth_coefficient, # 深度系数
        # 配置列表
        stackwise_kernel_sizes,  # 核大小
        stackwise_num_repeats, # 重复提取块的次数
        stackwise_input_filters, # 输入通道数
        stackwise_output_filters, # 输出通道数
        stackwise_expansion_ratios, # 扩张比例
        stackwise_strides, # 步长
        dropout_rate=0.2, # 在最终分类层之前的丢弃率。
        drop_connect_rate=0.2, # 在残差连接处的丢弃率。默认值设置为 0.2。
        depth_divisor=8, # 单位宽度
        input_shape=(None, None, 3), # 输入形状
        input_tensor=None, # 输入
        activation="relu6", # 激活函数
        **kwargs,
    ):
        # 模型输入
        img_input = utils.parse_model_inputs(input_shape, input_tensor)
        # 这里x会作为中间变量,做函数式的处理
        x = img_input
        if include_rescaling:
            x = keras.layers.Rescaling(1.0 / 255.0)(x) # 0--1
        # 填充,确保偶数尺寸时,也能正确填充
        x = keras.layers.ZeroPadding2D(
            padding=utils.correct_pad_downsample(x, 3), name="stem_conv_pad"
        )(x)
        # 第一次下采样(112,112,3)
        x = keras.layers.Conv2D(
            32,
            3,
            strides=2,
            padding="valid",
            use_bias=False,
            kernel_initializer=conv_kernel_initializer(),
            name="stem_conv",
        )(x)
        # 批次激活块
        x = keras.layers.BatchNormalization(axis=BN_AXIS, name="stem_bn")(x)
        x = keras.layers.Activation(activation, name="stem_activation")(x)

        # 处理块索引
        block_id = 0
        blocks = float(sum(stackwise_num_repeats)) # 处理块的总数
        # 对应金字塔层级的特征图列表
        pyramid_level_inputs = []
        # 遍历每一个层级的卷积
        for i in range(len(stackwise_kernel_sizes)):
            num_repeats = stackwise_num_repeats[i] # 当前层级的重复次数
            input_filters = stackwise_input_filters[i] # 当前层级的输入通道数
            output_filters = stackwise_output_filters[i]
            # 规范化输入输出通道(8的倍数)
            input_filters = round_filters(
                filters=input_filters,
                width_coefficient=width_coefficient,
                depth_divisor=depth_divisor,
            )
            output_filters = round_filters(
                filters=output_filters,
                width_coefficient=width_coefficient,
                depth_divisor=depth_divisor,
            )
            # 如果是第一个和最后一个层级
            if i == 0 or i == (len(stackwise_kernel_sizes) - 1):
                repeats = num_repeats
            else: # 其他情况
                repeats = round_repeats(
                    repeats=num_repeats,
                    depth_coefficient=depth_coefficient,
                )
            strides = stackwise_strides[i] # 当前使用相同配置的卷积步长
            # 遍历当前层级中的每个提取块
            for j in range(repeats):
                # 如果不是第一个块的话,步长==1,输入和输出通道数相同
                if j > 0:
                    strides = 1
                    input_filters = output_filters
                # 第一次下采样时,会把之前的特征图加入FPN
                if strides != 1:
                    pyramid_level_inputs.append(utils.get_tensor_input_name(x))
            
                # a...,这里预设的是块前缀
                letter_identifier = chr(j + 97)
                # 应用特征提取块
                x = apply_efficient_net_lite_block(
                    inputs=x,
                    filters_in=input_filters,
                    filters_out=output_filters,
                    kernel_size=stackwise_kernel_sizes[i],
                    strides=strides,
                    expand_ratio=stackwise_expansion_ratios[i],
                    activation=activation,
                    dropout_rate=drop_connect_rate * block_id / blocks,
                    name="block{}{}_".format(i + 1, letter_identifier),
                )
                block_id += 1 # 块索引

        # 经过所有提取块处理之后,要切换到的输出通道数,点卷积切换通道
        x = keras.layers.Conv2D(
            1280,
            1,
            padding="same",
            use_bias=False,
            kernel_initializer=conv_kernel_initializer(),
            name="top_conv",
        )(x)
        # 批次激活块,激活函数用于给线性的卷积增加非线性能力
        x = keras.layers.BatchNormalization(axis=BN_AXIS, name="top_bn")(x)
        x = keras.layers.Activation(activation, name="top_activation")(x)
        # FPN
        pyramid_level_inputs.append(utils.get_tensor_input_name(x))
        # 这个调用父类Model的方法构建模型
        super().__init__(inputs=img_input, outputs=x, **kwargs)
        # 保存这些设置为实例属性
        self.include_rescaling = include_rescaling
        self.width_coefficient = width_coefficient
        self.depth_coefficient = depth_coefficient
        self.dropout_rate = dropout_rate
        self.drop_connect_rate = drop_connect_rate
        self.depth_divisor = depth_divisor
        self.activation = activation
        self.input_tensor = input_tensor
        # 金字塔层级的提取模块,字典类型,idx-->name
        self.pyramid_level_inputs = {
            f"P{i + 1}": name for i, name in enumerate(pyramid_level_inputs)
        }
        # 配置列表
        self.stackwise_kernel_sizes = stackwise_kernel_sizes
        self.stackwise_num_repeats = stackwise_num_repeats
        self.stackwise_input_filters = stackwise_input_filters
        self.stackwise_output_filters = stackwise_output_filters
        self.stackwise_expansion_ratios = stackwise_expansion_ratios
        self.stackwise_strides = stackwise_strides
    # 这个用于设置配置字典,以便于之后的序列化
    def get_config(self):
        # 获取父类的配置字典
        config = super().get_config()
        config.update( # 加入子类特有的配置属性
            {
                "include_rescaling": self.include_rescaling,
                "width_coefficient": self.width_coefficient,
                "depth_coefficient": self.depth_coefficient,
                "dropout_rate": self.dropout_rate,
                "drop_connect_rate": self.drop_connect_rate,
                "depth_divisor": self.depth_divisor,
                "activation": self.activation,
                "input_tensor": self.input_tensor,
                "input_shape": self.input_shape[1:],
                "stackwise_kernel_sizes": self.stackwise_kernel_sizes,
                "stackwise_num_repeats": self.stackwise_num_repeats,
                "stackwise_input_filters": self.stackwise_input_filters,
                "stackwise_output_filters": self.stackwise_output_filters,
                "stackwise_expansion_ratios": self.stackwise_expansion_ratios,
                "stackwise_strides": self.stackwise_strides,
            }
        )
        return config
    # 类属性,预设配置
    @classproperty
    def presets(cls):
        return copy.deepcopy(backbone_presets)

model = EfficientNetLiteBackbone(
        input_shape=(224,224,3),
        stackwise_kernel_sizes=[3, 3, 5, 3, 5, 5, 3],
        stackwise_num_repeats=[1, 2, 2, 3, 3, 4, 1], # 相同卷积配置的提取深度
        stackwise_input_filters=[32, 16, 24, 40, 80, 112, 192],
        stackwise_output_filters=[16, 24, 40, 80, 112, 192, 320],
        stackwise_expansion_ratios=[1, 6, 6, 6, 6, 6, 6], # 扩张系数
        stackwise_strides=[1, 2, 2, 2, 1, 2, 1],
        width_coefficient=1.0,
        depth_coefficient=1.0,
        include_rescaling=False,
    )

model.pyramid_level_inputs.values()

dict_values(['block1a_project_bn', 'block2b_add', 'block3b_add', 'block5c_add', 'top_activation'])

images = np.ones((1,224,224, 3))
outputs = model.predict(images)

# 提取必要的参数
input_shape = (224, 224, 3)
stackwise_kernel_sizes = [3, 3, 3, 3, 3, 3]
stackwise_num_repeats = [2, 4, 4, 6, 9, 15]
stackwise_input_filters = [24, 24, 48, 64, 128, 160]
stackwise_output_filters = [24, 48, 64, 128, 160, 256]
stackwise_expansion_ratios = [1, 4, 4, 4, 6, 6]
stackwise_squeeze_and_excite_ratios = [0.0, 0.0, 0, 0.25, 0.25, 0.25]
stackwise_strides = [1, 2, 2, 2, 1, 2]
stackwise_conv_types = ["fused", "fused", "fused", "unfused", "unfused", "unfused"]
width_coefficient = 1.0
depth_coefficient = 1.0
include_rescaling = False
# 构建 EfficientNetV2-B0 模型
# 提取块浅层用的普通卷积,深层用的扩张点卷积+深度卷积组合
model = EfficientNetV2Backbone(
    input_shape=input_shape,
    stackwise_kernel_sizes=stackwise_kernel_sizes,
    stackwise_num_repeats=stackwise_num_repeats,
    stackwise_input_filters=stackwise_input_filters,
    stackwise_output_filters=stackwise_output_filters,
    stackwise_expansion_ratios=stackwise_expansion_ratios,
    stackwise_squeeze_and_excite_ratios=stackwise_squeeze_and_excite_ratios,
    stackwise_strides=stackwise_strides,
    stackwise_conv_types=stackwise_conv_types,
    width_coefficient=width_coefficient,
    depth_coefficient=depth_coefficient,
    include_rescaling=include_rescaling,
)

from keras_cv.src.models.backbones.efficientnet_v2.efficientnet_v2_backbone import EfficientNetV2Backbone

model=EfficientNetV2Backbone.from_preset('efficientnetv2_b2')

model.get_config()

{'name': 'efficient_net_v2_backbone',
 'trainable': True,
 'include_rescaling': True,
 'width_coefficient': 1.1,
 'depth_coefficient': 1.2,
 'skip_connection_dropout': 0.2,
 'depth_divisor': 8,
 'min_depth': 8,
 'activation': 'swish',
 'input_shape': (None, None, 3),
 'input_tensor': None,
 'stackwise_kernel_sizes': [3, 3, 3, 3, 3, 3],
 'stackwise_num_repeats': [1, 2, 2, 3, 5, 8],
 'stackwise_input_filters': [32, 16, 32, 48, 96, 112],
 'stackwise_output_filters': [16, 32, 48, 96, 112, 192],
 'stackwise_expansion_ratios': [1, 4, 4, 4, 6, 6],
 'stackwise_squeeze_and_excite_ratios': [0, 0, 0, 0.25, 0.25, 0.25],
 'stackwise_strides': [1, 2, 2, 2, 1, 2],
 'stackwise_conv_types': ['fused',
  'fused',
  'fused',
  'unfused',
  'unfused',
  'unfused']}

from keras_cv.src.models.backbones.efficientnet_v2.efficientnet_v2_backbone import EfficientNetV2Backbone

model=EfficientNetV2Backbone.from_preset('efficientnetv2_b2',input_shape=(224,224,3))

model.get_config()

model.summary()

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)      │ (None, 224, 224, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ rescaling_1 (Rescaling)         │ (None, 224, 224, 3)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ stem_conv (Conv2D)              │ (None, 112, 112, 32)   │           864 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ stem_bn (BatchNormalization)    │ (None, 112, 112, 32)   │           128 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ stem_activation (Activation)    │ (None, 112, 112, 32)   │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1a_ (FusedMBConvBlock)     │ (None, 112, 112, 16)   │         4,672 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block1b_ (FusedMBConvBlock)     │ (None, 112, 112, 16)   │         2,368 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2a_ (FusedMBConvBlock)     │ (None, 56, 56, 32)     │        11,648 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2b_ (FusedMBConvBlock)     │ (None, 56, 56, 32)     │        41,600 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block2c_ (FusedMBConvBlock)     │ (None, 56, 56, 32)     │        41,600 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3a_ (FusedMBConvBlock)     │ (None, 28, 28, 56)     │        44,768 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3b_ (FusedMBConvBlock)     │ (None, 28, 28, 56)     │       126,560 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block3c_ (FusedMBConvBlock)     │ (None, 28, 28, 56)     │       126,560 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4a_ (MBConvBlock)          │ (None, 14, 14, 104)    │        46,574 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4b_ (MBConvBlock)          │ (None, 14, 14, 104)    │       116,090 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4c_ (MBConvBlock)          │ (None, 14, 14, 104)    │       116,090 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block4d_ (MBConvBlock)          │ (None, 14, 14, 104)    │       116,090 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5a_ (MBConvBlock)          │ (None, 14, 14, 120)    │       183,962 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5b_ (MBConvBlock)          │ (None, 14, 14, 120)    │       229,470 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5c_ (MBConvBlock)          │ (None, 14, 14, 120)    │       229,470 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5d_ (MBConvBlock)          │ (None, 14, 14, 120)    │       229,470 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5e_ (MBConvBlock)          │ (None, 14, 14, 120)    │       229,470 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block5f_ (MBConvBlock)          │ (None, 14, 14, 120)    │       229,470 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block6a_ (MBConvBlock)          │ (None, 7, 7, 208)      │       293,182 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block6b_ (MBConvBlock)          │ (None, 7, 7, 208)      │       672,308 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block6c_ (MBConvBlock)          │ (None, 7, 7, 208)      │       672,308 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block6d_ (MBConvBlock)          │ (None, 7, 7, 208)      │       672,308 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block6e_ (MBConvBlock)          │ (None, 7, 7, 208)      │       672,308 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block6f_ (MBConvBlock)          │ (None, 7, 7, 208)      │       672,308 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block6g_ (MBConvBlock)          │ (None, 7, 7, 208)      │       672,308 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block6h_ (MBConvBlock)          │ (None, 7, 7, 208)      │       672,308 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block6i_ (MBConvBlock)          │ (None, 7, 7, 208)      │       672,308 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ block6j_ (MBConvBlock)          │ (None, 7, 7, 208)      │       672,308 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ top_conv (Conv2D)               │ (None, 7, 7, 1408)     │       292,864 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ top_bn (BatchNormalization)     │ (None, 7, 7, 1408)     │         5,632 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ top_activation (Activation)     │ (None, 7, 7, 1408)     │             0 │
└─────────────────────────────────┴────────────────────────┴───────────────┘

 Total params: 8,769,374 (33.45 MB)

 Trainable params: 8,687,086 (33.14 MB)

 Non-trainable params: 82,288 (321.44 KB)

从这里可以清楚看到effinetv2的架构,较浅的层用的FusedMBConvBlock,较深的层用的MBConvBlock,所谓融合,其实并非融合,你可以理解成用标准卷积替换了MBConv中的扩张点卷积和深度卷积,没有se模块,残差部分是较小通道的点卷积,所谓MBConv,是固定的一个套路,压缩点卷积(残差前段)-->扩张点卷积-->深度卷积-->se模块-->压缩点卷积(残差后段),别人说这个是窄宽窄,你得知道他为啥这么说,因为残差的两部分是不是用的较小的通道数,而中间特征处理的部分是不是用的较大的通道数,所以说它是窄宽窄,v1时,他用的都是MBConv,v2改变了架构,前面用的FusedMBConvBlock,,后面用的MBConv,AI说是浅层网络一般提取边缘,纹理,这时用标准卷积提取效果更好,而较深层时,一般是形状之类的较抽象的语义特征,这时用MBConv效果好,但是你不能因为effinet用的这种架构就说它好,resnet用的另一种架构就说resnet好,我的理解和AI多少有些不同,在较浅层网络时,用扩张通道的标准卷积提取特征,参数量不会那么明显的大,因为浅层网络宽度一般较窄,而网络较深时,你这时再用扩张通道后的标准卷积,那参数量不是一般的大,这时,effinet用的就是扩张点卷积+深度卷积的形式,原因最重要的应该是减少参数量,因为effinet主要就是在不牺牲性能的情况下减少计算量,所以我的理解是你要是不怕计算量,深层也可以用那种FusedMBConvBlock,这时可以带上se模块,V2还有一个点,随深度加深,dropout率递增.它在提取块内输出点卷积那里用了dropout
